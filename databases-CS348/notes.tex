\documentclass{article}
\usepackage{parskip}
\usepackage[margin=.6in]{geometry}
\usepackage{hyperref}



\begin{document}
\subsection{Compotentes}
\paragraph{Data}
Logical view and physical view of data. Logical view is what is seen by the programmers of the application and the physical view is what is seen by the system

\paragraph{People}
The users are the ones who pay for the system, we need to assume that they know nothing about the system (end user).

Administator is the one who charge of the database.

\section{1.4 Procedure}
We have large complex data models, but we need a way to populate it with data (need to implement).

We want to reduce the dependencies between programs and data. If we change the data it should have minimal effect on the program (UI excepted). Similarly we want very little change to data when the program is changed. This cannot be eliminated, but reduced.

Three levels (external, conceptual, internal) that each have their own schemas, called the three shema approach
\paragraph{external schema} view for users

\paragraph{conceptual schema} integrates external schema

\paragraph{internal schema} defined physical storage
Three schema approach: \url{https://en.wikipedia.org/wiki/Three_schema_approach}.

When we change the application program only the external schema should change to fit it, maybe the conceptual a bit, but not the internal schema

\subsection{Language facilities}
\paragraph{Data Definition Language (DDL)} - specifies conceptual schema and subschemas and the mappings between them.
\paragraph{Data dictionary, data directory or system catalog} - result of compilation of DDL statements in a schema; metadata.
\paragraph{Data manipulation language (DML)} - commands issued in a host program and preprocess or compiler interprets these commands as calls to DBMS. (SQL is default)
\paragraph{Query language} – a complete language for manipulating data interactively. Should be user friendly but not super powerful (interactive SQL is default)

\subsection{Data Models}
Value based model requires an attribute that can uniquly identify an object, Object based model does not.

\subsection{Database Design Process}
Identify functional requirements. From there figure out what data is required for those requirements, called database requirements. Structure this data in a understandable way (make a conceptual schema). This is where we make a entity relationship model. We use entity relationship models in the conceptual and logical (internal) schemas.

\subsection{Entity Relationship Model}
Invented in 70s and grew in popularity as variations were created, so we have a family of entity relationship models. These can get complicated and hard to read (we use a specific form of notation). An entity is something that has independent existence that is relevant to application. A single value attribute (for example a telephone) has only one value. Multivalue attributes are attributes that might have multiple parts to them (like an address). Some attributes don't belong to anyone and instead describe the relationships between them. Enities in a relationship type model dont have to have a primary key to be used.

\begin{itemize}
    \item rectangle - entity type
    \item diamond - relationship type
    \item circles - attributes
\end{itemize}

Binary relationship is between two entity types.

\subsection{Aggregation} % (fold)
\label{sub:aggregation}
Aggregation is the grouping of entities that have a connected relationship and only one connection outside that group to the rest of the entity map we can redraw the map with those entities grouped into one entity
% subsection aggregation (end)

\subsection{Clustering} % (fold)
\label{sub:clustering}
Store chuncks to data together to make accessing it faster. Try to store a bunch in memory buffer to limit the number of times we need to read.
% subsection clustering (end)


\subsection{Ordered Files} % (fold)
\label{sub:ordered_files}
These make searching for specific files much easier (using a binary search since their order is maintained). Whenever you change the main data file all its elements need to be indexed.

\paragraph{B+ tree} store the largest index of a block in its parent. There are three techniques, merging, splitting, and distribution. Everything is based on primary key value. The data block is represented by linked pages. Basically store the min and max values of each block in its parent block and you can just run a binary search (note: data must be sorted).
% subsection ordered_files (end)

\subsection{Relation Scheme} % (fold)
\label{sub:relation_scheme}
See the big ass example in lecture notes, page 85.
% subsection relation_scheme (end)

\section*{Relational Algebra} % (fold)
\label{sec:relational_algebra}
Relational tables require all rows to be unique as designated by the primary key (you must have at least one candidate key that is not updated or null). Foreign keys can be used to reference rows in other tables.

\begin{verbatim}
table_constraint:=
    [CONSTRAINT name]
    {UNIQUE (<column name> + ) |
    PRIMARY KEY (<column name> + ) |
    FOREIGN KEY (<column name> + )
    REFERENCES <table name> [ON {UPDATE |
    DELETE} <effect>]}
<effect> := SET NULL | NO ACTION
    (RESTRICT) | CASCADE | SET DEFAULT
\end{verbatim}

\paragraph{Union operation} % (fold)
\label{par:union_operation}
This operation combines two tables if they have the same attributes (all the same columns) and deletes any duplicates. Denoted by $\cup$.
% paragraph union_operation (end)
\paragraph{Set Difference} % (fold)
\label{par:set_difference}
This operation returns any elements in one table that are not in  the other (tables must have same attributes). R-S results in values that are in R and not in S. Denoted by $-$.
% paragraph set_difference (end)
\paragraph{Projection} % (fold)
\label{par:projection}
This operation removes or rearranges columns. R(A,B,C) $\rightarrow$ $\pi_{C,A}(R) = R(C,A)$. Denoted by $\pi_{columns}(TABLE)$.
% paragraph projection (end)
\paragraph{Selection} % (fold)
\label{par:selection}
This operations returns rows in a table that satisfy conditions. Denoted by $\sigma_{conditions}$.
% paragraph selection (end)
\paragraph{Cartesian Product} % (fold)
\label{par:cartesian_product}
This operation combines two tables by taking their Cartesian product (make all possible combinations of rows). (A, B) X (C D, E F) = (A C D, A E F, B C D, B E F). Denoted by $\times$.
% paragraph cartesian_product (end)
\paragraph{Rename} % (fold)
\label{par:rename}
This operation renames columns. Denoted $\rho_{table(columns)}(TABLE)$.
% paragraph rename (end)
\paragraph{Natural Join} % (fold)
\label{par:natural_join}
This joins two tables based on a shared attribute. Think of a cartesian product but only for rows that have matching attributes. Denoted by $*$.
% paragraph natural_join (end)
\paragraph{Binary Relational} % (fold)
\label{par:binary_relational}
This operation is a sub operation on natural joins that provides a condition to the join to only include rows that satisfy the condition. This is equivalent to running the set operator on a cartesian product. $R*S_{\theta condition} := \sigma(R\times S)$. Denoted $\sigma$.
% paragraph binary_relational (end)
\paragraph{Intersection} % (fold)
\label{par:intersection}
This operation returns any rows that are in both tables (tables must have matching attributes). Denoted $\cap$.
% paragraph intersection (end)
% section relational_algebra (end)

\section{Views} % (fold)
\label{sec:views}
Views are just a virtual table that compute dynamically.

To create a view:
\begin{verbatim}
    CREATE VIEW <view name> (<list of column names>)
        AS <subquery> <with check option>
\end{verbatim}
Where the subquery is the selector of what rows are in the view (views are subsets of tables). The with check option says that any operations to the view that would be invisible to the view (ie. not fit the selector for the view) wouldn't be allowed.

To delete a view:
\begin{verbatime}
    DROP VIEW <view name>
\end{verbatime}

When updating a view you run into a problem if the view's data is representative of a calculation done on the underlying table (imaging a column of sums). You cannot update this data because it would be inaccurate as updating a view doesn't touch the underlying table. There is no good way to do this aside from putting in restrictions on what you can an cannot update.
% section views (end)
\section{Embedded SQL} % (fold)
\label{sec:sql_basics}
\textbf{Intearctive SQL}: statements are input from the terminal

\textbf{Non-inteactive SQL}: compiled in the application language

\textbf{Statement Level Interface}: application mixes in sql statements to their host language (usually have special syntax to tell sql from host language), the precompiler finds sql and translates it into calls to the host language which is then compiled by the host language compiler and executed. These can be static or dynamic sql.

\textbf{Call Level Interface}: sql statements are passed around as strings that are executed by the host language
% section sql_basics (end)

\section{Static SQL} % (fold)
\label{sec:static_sql}
VARCHAR: oracle data type is how we get variables. Variables that are referenced by sql statements are \textbf{host variables} and prefixed with a colon. These must be defined within an embeded sql declaration section
% section static_sql (end)

\subsection*{Cursor Operations} % (fold)
\label{sec:cursor_operations}
A cursor is created by EXEC SQL DECLARE <curson name>. INSENSITIVE option creates a copy of the rows in the result set and all accesses through the cursor will be to that copy. If this is not specified then we are working with the actual row and can edit it (unless read only is declared). OPEN operation executes the query related to the cursor and we can use a couple of operations to advance it (FIRST, NEXT, PRIOR, etc). We need to specify SCROLL when declaring the cursor to use these operators, else only NEXT is allowed. We then give the cursor declaration a FOR

% subsection* cursor_operations (end)

\subsection*{Update Operation} % (fold)
\label{sec:update_operation}
this updates the current row that the cursor is pointing at with the given values.
% subsection* update_operation (end)

Some cursor update sample code
\begin{verbatim}

\end{verbatim}
exec sql declare cursor c for ...;
exec sql open cursor c;
while (true){
    exec sql fetch c into :var ...;
    exec sql update <table> set <attribute> = <expr>
    where current of c;
    exec sql commit work;} //commit or rollback signals the end of work

\section{Dynamic SQL} % (fold)
\label{sec:dynamic_sql}
This allows you to execute commands where you dont know the full context at the time. May have slower performance as things are stored in strings then prepared and executed instead of straight execution. we many even use dummy host variables which dont need to be declared.

If you want to execute immediately you can use EXECUTE IMMEDIATE <variable the statement is stored in>. Else you prepare by processing into static sql using the PREPARE <statement name> FROM <statement command>, then we execute by passing in a parameter list that will substitute for dummy values using the EXECUTE <statement name> [INTO <variable list>][USING <parameter list>].

% section dynamic_sql (end)

Here we use cursors the same way by declaring them with OPEN.

\section{JDBC} % (fold)
\label{sec:jdbc}
This is a CLI for executing SQL in a Java program. The statement is constructed at run time as a java variable which is then passed to an underlying dbms through a driver.

We connect to the data based, send statements, then process the results. See notes for sample code.

Connect to database with DriverManager.getConnection(url, id, password) if successfull it creates a connection object (called con from now on)

Create a statment object with con.createStatement(), these have executeQuery and executeUpdate abilities. Called stat.

We then assign a query string (just a string of sql) to with through stat.executeQuery(string) which returns a set of of results. Query string can have variables in it as it is constructed at run time.

We prepare the query string used above with con.prepareStatement(string). We mark placeholders with ? where actual values are plugged in using the preparedStatement's setString function (takes a index and value to put there). We can then run the executeQuery function on thsi prepared string.

We can get data from a column using getTYPE function
\begin{verbatim}
while ( res.next ( ) ) { // advance the cursor
    j = res.getString (“COF_NAME”); // fetch output value
    ...process output value...
}

could also have passed in the column index.
\end{verbatim}
% section jdbc (end)

\section{Schema Analysis} % (fold)
\label{sec:schema_analysis}
This is where shit gets weird.

Notation
\begin{itemize}
    \item R, X, Y, Z - sets of attributes or relation schemes.
    \item r - a relation defined on a relation scheme R.
    \item s, t, u, v - tuples defined on some relation scheme.
    \item A, B, C, D, E - single attributes.
    \item ABC - a set consists of the attributes A, B and C.
    \item F, G, H - sets of functional dependencies.
    \item f, g, h - single functional dependencies.
    \item Let t be a tuple. Then t[X] denotes the X components of t.
\end{itemize}

\subsection*{Functional Dependencies} % (fold)
These are denoted as fd's. For example a relationship r \textbf{satisfies} $X\rightarrow Y$ if whenever two tuples in r agree on their X components they also agree on their Y components. Basically it denotes instances where the values in one column are dependant on another (for example all cars in the canada are tax free so the tax column relies on the country column).

$X\rightarrow Y$ is \textbf{trivial} if Y is a subset of X.

A fd g is \textbf{implied} by f (denoted by F |= g) if whenever r satisfies F it satisfies g.

The \textbf{closure} of a set of fd's F, $F^+ = \{X\rightarrow Y | F |= X \rightarrow Y\}\]$. This means that the closure of F ($F^+$) is the set of all dependencies such that F logically implies those dependencies

A fd's F is a \textbf{cover} (meaning equal to) of G (denoted $\approx$) if $F^+ = G^+$. This means that two sets of dependencies are considered equal to each other if they have the same closure (logically imply the same set of dependencies).

The \textbf{closuer} of a set of attributes X is $X^+ = \{A | X\rightarrow A is in F^+\}$. This is the set of all attributes that have a dependency to the chosen attribute (X) as defined by some dependency closure($F^+$).

X is a \textbf{candidate key} of R if $X\rightarrow R\in F^+$ and no proper subset of X has this property. Translated, for a set of attributes R, an set of attributes X is a candidate key of that set if the dependency of X to R exists in the given closure of dependencies $F^+$ and no subset of X can fulfill this property (candidate key must be minimal).

Y is a \textbf{superkey} of R if Y contains a key of R (where Y and R are sets of attributes).

\textbf{Theorem}: Given F, XY is a subset of R then:
\begin{itemize}
    \item $F|= XY$
    \item Y is a subset of $X^+$
\end{itemize}
This means that for a set of dependencies F and two sets of attributes X and Y that are a subset of a larger set of attributes R we can say that if F logically implies that X has a dependency Y then Y is a subset of the attribute cover of X, $X^+$, and vice versa.

\textbf{Theorem}: Let $Y=A_1 ... A_n$ then $F|=X\rightarrow Y$ iff $F|=X\rightarrow A)n$ and ... $F|=X\rightarrow A_n$
This means that for a set of n attributes Y, we can only say F logically implies the dependency of X to Y if it implies the dependencies of X to each attribute in Y.

F is a \textbf{minimal conver} if
\begin{itemize}
    \item every right side of a dependency in F is a single attribute
    \item there exists no $X\rightarrow A$ in F such that $F-\{X\rightarrow A\}\]\approx F$ (if you removed the dependency F would cover itself, ie no dependency is negligible)
    \item there exists no $X\rightarrow A$ in F and a proper Z of X such that $F-\{X\rightarrow A\}\]\cup\{Z\rightarrow A\}\]\approx F$ (there is no subset of X that if its dependencies were removed F would cover itself, ie no subset of X is negligible)
\end{itemize}

\textbf{How to compute closer}: given a set of dependencies F and a set of attributes X. First define the closure set to equal X so that it is nonempty. For each dependency in F, if the lhs is a subset of the current closure set and the rhs is not in the closure set then add the rhs to the closure set. At the end of this loop you will have computed the closure for X ($X^+$).

% section schema_analysis (end)

\section{Decomposition} % (fold)
\label{sec:decomposition}
We can break up a large table into a series of smaller tables by creating a new table for each dependency in the main table.

An attribute A in a set of attributes R is \textbf{prime} if it is in X for some candidate key X. Basically a prime attribute is an attribute in a candidate key for a set of dependencies R (think of R as a table).

\section{Normal Form} % (fold)
\label{sec:normal_form}
\textbf{First Normal Form}: denoted 1NF, attributes are atomic meaning they have no internal fields (at least none that the relations and schemas care about), an example of a violation of this is if you had a relation between parent and a list child (we cannot query individual children in this relation), to solve this we create an entry for each parent child relation (multiple entries for each parent)

\textbf{Second Normal Form}: denoted 2NF, this requires it to be 1NF and have any non-prime attributes depend on a candidate key (all of the key, not a subset), an example of a violation would be if the example solution to 1NF incorperated the gender of parents so that the parent to child relation was a candidate key (since this is unique) and the gender of parent is non-prime (cannot form a candidate key using it and anything else) but it doesn't depend on the parent-child candidate key. To fix this you need to make a new parent to gender table where this pairing works.

\textbf{Third Normal Form}: denoted 3NF, requires it to be 2NF and have no dependencies among any of the non-prime attributes, an example violation would be if the solution to 2NF example included a type of parent (father or mother) that is dependant on gender of parent, but both of these are non-prime keys (arent part of candidate key). To fix this you take out the type of parent value from table and create a new table for gender to type relation.
% section normal_form (end)


%stopped at page 211

\end{document}
